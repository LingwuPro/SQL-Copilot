# SQL-Copilot：离线可用的database-aware代码生成模型

**灵乌 & kk** **多媒体大作业项目仓库**



## 项目介绍

本项目基于llama和spider数据集，我们实现了一个可以根据数据集产生离线代码生成的大模型， 同时我们使用了一系列优化和剪枝技术， 成功的将模型达到CPU可用级别， 其速度与单卡A100做llama2-7B相差无二。而且本模型很小， 仅需要8g运存， 大部分服务器完全可搭载，方便进行数据库级别的大模型生成。

## Our work

- 基于spider数据集, 实现了一个新的测评框架, 使用sqllite, 保证了即使其模型的输出与标准答案不同, 只要查询结果是一致的, 就判断返回正确的程序. 基于此框架, 其优化了huggingface的train函数----当查询结果与正确答案不同时, 使用标准答案为right answer, 以tokenizer编辑距离为依据做反向传播; 当结果正确时,直接判定正确. 这样的Optimization设置可以极大地提高优化效率, 收敛速度加速.
- 模型结构化剪枝+模型蒸馏: 在llama经过spider数据集的finetune之后,其对模型进行结构化剪枝, 在基本不影响其在spider数据集效果的前提上, 将模型压缩到12%; 最后将剪枝模型作为student, 将原tune过之后的模型作为teacher进行单层蒸馏训练10个epoch.
- 将模型通过query激活转化为计算图, 将原本动态模型转化为静态图, 进一步降低显存和计算量. 最后使用pytorch的jit将此计算图嵌入到C++框架, 成为C++可调用的模型. 由于tokenizer本身计算量不大, 因此没有将其转为C++计算图. 至此, 此模型已经完全可以做到CPU可用.

## 结构化剪枝 & 蒸馏介绍

结构化剪枝是深度学习领域中的一个重要概念，它是指同时移除神经网络中的一组权重连接，例如整个通道或滤波器。这与非结构化剪枝不同，非结构化剪枝是指单独移除网络中的个别权重连接。结构化剪枝会改变层的输入和输出形状以及权重矩阵，因此几乎每个系统都可以成功地更快地运行结构化剪枝的网络。然而，结构化剪枝严重限制了可以施加在网络上的最大稀疏度，因此严重限制了性能和内存的改进。这是因为剪枝权重组和整个通道会带走灵活性，必要的连接也会被剪掉。从实际角度来看，当剪枝通道或滤波器时，层的宽度（以及整个网络）会减小，从而将网络进一步推向离原始状态更远的位置。因此，结构化剪枝通常会导致更少的性能和内存改进，但它可以在预测时间更快地运行网络，并且可以在磁盘上以更少的空间存储压缩的模型文件。

知识蒸馏是一种将大型模型或模型集合中的知识转移到单个较小模型的过程。这有助于在实际约束条件下部署模型，尤其是在边缘设备上，这些设备具有有限的内存和计算能力。知识蒸馏的目标是通过训练一个小型模型来模仿大型模型，以获得类似或更高的准确性，同时避免显著的性能损失。这种方法最初由Bucilua和合作者在2006年成功演示，后来由Hinton和同事正式提出并命名为“知识蒸馏”框架。知识蒸馏系统通常包括三个主要组成部分：知识、蒸馏算法和师生架构。在神经网络中，知识通常指的是学习到的权重和偏置。大型深度神经网络中的知识来源多种多样，包括输出层的对数、中间层的激活值等。知识蒸馏可以使用师生模型架构，其中小“学生”模型学习模仿大“老师”模型，并利用老师的知识来获得类似或更高的准确性。在知识蒸馏中，有三种不同类型的知识：基于响应的知识、基于特征的知识和基于关系的知识。基于响应的知识关注老师模型的最终输出层，学生模型通过最小化蒸馏损失函数来学习模仿老师模型的预测。基于特征的知识和基于关系的知识则关注中间层的激活值和神经元之间的关系。这些不同类型的知识可以帮助学生模型更好地学习和模仿老师模型的知识。知识蒸馏的应用包括图像识别、文本处理和语音识别等领域。通过知识蒸馏，可以将大型模型的知识转移到小型模型，从而在实际部署中更好地满足性能和资源约束。

## 模型计算图 & 转化

计算图是深度学习中用于表示数学运算的图形化结构。计算图由节点和边组成，节点代表数学运算，边代表数据流向。在深度学习中，计算图通常用于表示神经网络的结构和计算过程。计算图可以分为静态计算图和动态计算图。静态计算图在运行之前就已经定义好，例如TensorFlow 1.x中的计算图。而动态计算图是在运行时动态构建的，例如TensorFlow 2.x和PyTorch中的计算图。在计算图中，节点通常表示各种数学运算，例如加法、乘法、激活函数等。边则表示数据的流动，即运算的输入和输出。通过计算图，可以清晰地展现出数据在神经网络中的流向和各个节点之间的关系，有助于理解和优化神经网络的计算过程。

当将PyTorch的模型从Python转换为C++时，可以使用PyTorch的TorchScript功能。TorchScript是一种将PyTorch模型转换为可序列化和可优化模型的方法。通过TorchScript，可以将模型保存为一个文件，然后在没有Python依赖的环境中加载和执行。

## 环境配置

python包环境见requirement.txt；

```
pip install -r requirement.txt
```

除python包环境外，其他基本相关环境有

```
python >= 3.10.0
cmake >= 3.27.0
```

## 运行方法

已经压缩好的静态模型可以联系我获取，由于种种原因没有上传huggingface。如果你想从头开始重新训练一个tiny版sql-copilot，首先你需要下载llama2-7B，代码中有默认获取方式，请确保有足够的内存进行存储；下载完成后，运行

```
python spider.py
```

即可开始压缩与蒸馏；参考时长， 若训练两个epoch（基本收敛数量）再加3个epoch的蒸馏训练， 时长在8h左右。

然后运行静态压缩脚本，即

```
python jit.py
```

然后将你需要的内容输入到josn文件中， 最后运行run.sh即可。
